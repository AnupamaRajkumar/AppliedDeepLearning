{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SuperResolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOz1uEo2ooltvS3oq7PtXCF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnupamaRajkumar/AppliedDeepLearning/blob/master/SuperResolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJrJcMIUcC9f"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwfba0if-93A"
      },
      "source": [
        "## Prepare dataset\n",
        "\n",
        "### BSDS300\n",
        "* LR: Low resolution, HR: high resolution, SR: super resolution\n",
        "* Download the BSDS300 dataset. Here you can find more information about the dataset: https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/\n",
        "* After extracting it, convert them to YCrCb color space. We will use the luminance information (0th channel) only as the input of the CNN.\n",
        "* Create 32x32 image patches with a sliding window (16 step size).\n",
        "* Use 0.15 part of the train set as the validation set.\n",
        "* The Y (0th) channel of the original images will be the ground truth. Create the LR images by resizing them half of the original size, then resize it back to the original size using cubic interpolation.\n",
        "* Print the size of each set and plot 5 LR training images and their corresponding HR images. *Note: Don't forget to convert the color space from YCrCb back to RGB before plotting.*\n",
        "* Normalize the datasets. All value should be between 0.0 and 1.0. *Note: you don't have to use standardization, you can just divide them by 255.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdVOB_f3KAnk"
      },
      "source": [
        "Downloaded the BSDS300 dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMSpWBX2Gk6D"
      },
      "source": [
        "# BSDS300 dataset\n",
        "!wget https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300-images.tgz\n",
        "!tar -xvzf BSDS300-images.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoFzLzLUHmLZ"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import skimage\n",
        "import sklearn\n",
        "import PIL\n",
        "import PIL.Image"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLtMjuhIOEpk"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD3jVtaBOV1S"
      },
      "source": [
        "Accessing training folder paths and creating folder for saving the pre-processed datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVGArY9CbL4b",
        "outputId": "fd1e3041-8713-461e-da5b-5d696132b2be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "path = '/content/BSDS300/images'\n",
        "train_path = os.path.join(path, 'train')\n",
        "print(train_path)\n",
        "tfd_train_path = os.path.join(path, 'tfd_train')\n",
        "if not os.path.exists(tfd_train_path):\n",
        "  os.mkdir(tfd_train_path)\n",
        "print(tfd_train_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BSDS300/images/train\n",
            "/content/BSDS300/images/tfd_train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPn8_ZgT_nyg"
      },
      "source": [
        "Crop the training data into patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VAyYRPM_nd8"
      },
      "source": [
        "def generatePatches(img, img_idx):\n",
        "  height, width, _ = img.shape\n",
        "  h = 0\n",
        "  w = 0\n",
        "  patchSize = 32\n",
        "  stride = 16\n",
        "  patches = []\n",
        "  while( h < height and (height - h > patchSize)):\n",
        "    while(w < width and (width - w > patchSize)):\n",
        "      patch = img[h:h+patchSize, w:w+patchSize]\n",
        "      patches.append(patch)\n",
        "      w = w + stride\n",
        "    h = h + stride\n",
        "  return patches"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtRRdhbo4KU7"
      },
      "source": [
        "Convert RGB image to YCrCb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYpJe94z3gFY"
      },
      "source": [
        "def convertBGRToYCrCb(img):\n",
        "  YCrCbImg = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "  return YCrCbImg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3An85k24N47"
      },
      "source": [
        "Convert YCrCb image to RGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqkS8gV83z4Z"
      },
      "source": [
        "def convertYCrCbToRGB(img):\n",
        "  RGBImg = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
        "  return RGBImg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeN7vhBe9Cgn"
      },
      "source": [
        "Convert the images to YCrCb color space, create image patches and save as training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhPbxh1jOEZ4"
      },
      "source": [
        "def transformTrainingSamples(train_path, tfd_train_path):\n",
        "  os.chdir(train_path)\n",
        "  for img_idx in os.listdir(train_path):\n",
        "    img_name = cv2.imread(img_idx)\n",
        "    newImg = convertBGRToYCrCb(img_name)\n",
        "    os.chdir(tfd_train_path)\n",
        "    #create 32x32 patches of these images with 16 step size\n",
        "    patches = generatePatches(newImg, img_idx) \n",
        "    #save this training dataset\n",
        "    cnt = 0\n",
        "    for p in patches:\n",
        "      cnt = cnt + 1\n",
        "      img_name = str(cnt) + '_' + img_idx\n",
        "      print(img_name)\n",
        "      cv2.imwrite(img_name, p)\n",
        "    os.chdir(train_path)\n",
        "  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_gWcaY9_33b"
      },
      "source": [
        "transformTrainingSamples(train_path, tfd_train_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXt7dN3cBu3X",
        "outputId": "78847e63-fbea-49f8-865e-19e9cef4157c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import glob\n",
        "os.chdir(tfd_train_path)\n",
        "print(os.getcwd())\n",
        "\n",
        "files = glob.glob(\"*.jpg\")\n",
        "imgLst = []\n",
        "for myFile in files:\n",
        "  image = cv2.imread(myFile)\n",
        "  image = np.array(image)\n",
        "  imgLst.append(image)\n",
        "\n",
        "imgArr = np.array(imgLst)\n",
        "print(imgArr.shape)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BSDS300/images/tfd_train\n",
            "(5170, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T872zuNLCuIY"
      },
      "source": [
        "Split the patches into training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0bEz6sOLQAr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_ds, val_ds = train_test_split(imgArr, test_size = 0.15, shuffle = True)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNR-zCSjNBwK",
        "outputId": "b062bd17-2fde-40d0-930a-f15f62dcb3ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(\"shape of training set\", train_ds.shape)\n",
        "print(\"shape of validation set\", val_ds.shape)\n",
        "print(type(train_ds))\n",
        "print(type(val_ds))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of training set (4394, 32, 32, 3)\n",
            "shape of validation set (776, 32, 32, 3)\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL-Fw12-lC-B"
      },
      "source": [
        "Creating low resolution images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN6dQNRSlIFt"
      },
      "source": [
        "def createLowResolutionImage(img):\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43Fz9p7fPjxL"
      },
      "source": [
        "Normalise the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxvVW1cWPhxf",
        "outputId": "c67d48eb-4233-4c88-e059-8b8a965470fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_ds_norm = (train_ds / 255.0)\n",
        "val_ds_norm = (val_ds / 255.0)\n",
        "\n",
        "print('Scale of the training samples:', (np.min(train_ds_norm), np.max(train_ds_norm)))\n",
        "print('Scale of the training samples:', (np.min(val_ds_norm), np.max(val_ds_norm)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scale of the training samples: (0.0, 1.0)\n",
            "Scale of the training samples: (0.0, 1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}